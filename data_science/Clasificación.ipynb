{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13feeed",
   "metadata": {},
   "source": [
    "# Temas: Clasificación\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-sponsorship",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "## Taller de Ciencia de Datos\n",
    "### Omar Piña Ramírez\n",
    "### Instituto Nacional de Perinatología\n",
    "### Departamento de Bioinformática y Análisis Estadísticos\n",
    "### Investigador en Ciencias Médicas\n",
    "### delozath@gmail.com\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:1500px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    ".CodeMirror{\n",
    "    font-size: 15px;\n",
    "}\n",
    "\n",
    ".rendered_html table, .rendered_html td, .rendered_html th {\n",
    "    font-size: 120%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-sailing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from   matplotlib import pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from   ipywidgets import interact, interact_manual, FloatSlider, Layout\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs   as go\n",
    "import plotly.express      as px\n",
    "from   plotly.offline      import iplot, init_notebook_mode\n",
    "\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode (connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-disposition",
   "metadata": {},
   "source": [
    "## Aprendizaje supervisado -> Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-straight",
   "metadata": {},
   "source": [
    "### Datos sintéticos de archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-jurisdiction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = './data/'\n",
    "file = 'blobs.csv'\n",
    "\n",
    "df_blobs = pd.read_csv(PATH + file)\n",
    "df_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blobs['Label'] = df_blobs['Label'].astype('int')\n",
    "df_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-feedback",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'width':700, 'height':700, 'color_discrete_sequence':['black','orange']}\n",
    "@interact\n",
    "def scatter_plot(n_samples=(50,5000,100)):\n",
    "    fig = px.scatter(df_blobs.loc[:n_samples], x='X0', y='X1', color='Label', **params)\n",
    "    fig.update_traces(marker={'size': 9})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-sensitivity",
   "metadata": {},
   "source": [
    "### 1. Scrubbing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-venture",
   "metadata": {},
   "source": [
    "### 2. Prevalencia de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-technical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def hist_plot(x=df_blobs.columns):\n",
    "             df_blobs[x].iplot(kind='hist', x=x, \n",
    "             xTitle=x.title(),  \n",
    "             title=f'Histograma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-current",
   "metadata": {},
   "source": [
    "### 3. Split: Train-Test-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "NT    = 0.8\n",
    "NV    = 1 - NT\n",
    "N     = df_blobs.shape[0]\n",
    "index = np.arange(N)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "tune     = index[:int(NT*N)]\n",
    "validate = index[-int(NV*N):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_blobs.iloc[tune][['X0','X1']]\n",
    "y = df_blobs.iloc[tune][['Label']]\n",
    "\n",
    "X_Val = df_blobs.iloc[validate][['X0','X1']]\n",
    "y_Val = df_blobs.iloc[validate][['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.metrics         import recall_score as sensitivity\n",
    "\n",
    "k     = 10\n",
    "sf    = ShuffleSplit(n_splits=k,test_size=.25)\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "sen_perform = []\n",
    "spe_perform = []\n",
    "for train,test in sf.split(X,y):\n",
    "    model.fit(X.iloc[train],y.iloc[train].values.ravel())\n",
    "    L   = model.predict(X.iloc[test])\n",
    "    sen = sensitivity(y.iloc[test],L)\n",
    "    spe = sensitivity(y.iloc[test],L,pos_label=0)\n",
    "    print(\"Sensitivity: {:.3f}, Specificity: {:3f}\".format(sen,spe))\n",
    "    sen_perform.append(sen)\n",
    "    spe_perform.append(spe)\n",
    "\n",
    "sen_perform = np.array(sen_perform)\n",
    "spe_perform = np.array(spe_perform)\n",
    "print(\"\\nPerformance\")\n",
    "print(\"Sensitivity: {:.3f} ± {:.3f}\".format(sen_perform.mean(),sen_perform.std()))\n",
    "print(\"Specificity: {:.3f} ± {:.3f}\".format(spe_perform.mean(),spe_perform.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "\n",
    "model.fit(X,y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "L   = model.predict(X_Val)\n",
    "sen = sensitivity(y_Val,L)\n",
    "spe = sensitivity(y_Val,L,pos_label=0)\n",
    "\n",
    "print(\"Sensitivity: {:.3f}, Specificity: {:3f}\".format(sen,spe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix as plt_cm\n",
    "\n",
    "plt_cm(model,X_Val,y_Val,cmap='inferno')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-delicious",
   "metadata": {},
   "source": [
    "### Datos Infarto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-boost",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = 'cardiovascular.csv'\n",
    "\n",
    "data  = pd.read_csv(PATH + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-queens",
   "metadata": {},
   "source": [
    "### Scrubbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {'famhist':{'Present':1,'Absent':0}}\n",
    "data    = data.drop(columns='ind')\n",
    "data    = data.replace(replace)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "NT    = 0.8\n",
    "NV    = 1 - NT\n",
    "N     = data.shape[0]\n",
    "index = np.arange(N)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "tune     = index[:int(NT*N)]\n",
    "validate = index[-int(NV*N):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age']\n",
    "lab  = 'chd'\n",
    "X    = data.iloc[tune][cols]\n",
    "y    = data.iloc[tune][lab]\n",
    "\n",
    "X_Val = data.iloc[validate][cols]\n",
    "y_Val = data.iloc[validate][lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.metrics         import recall_score as sensitivity\n",
    "\n",
    "k     = 10\n",
    "sf    = ShuffleSplit(n_splits=k,test_size=.25)\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "sen_perform = []\n",
    "spe_perform = []\n",
    "for train,test in sf.split(X,y):\n",
    "    model.fit(X.iloc[train],y.iloc[train].values.ravel())\n",
    "    L   = model.predict(X.iloc[test])\n",
    "    sen = sensitivity(y.iloc[test],L)\n",
    "    spe = sensitivity(y.iloc[test],L,pos_label=0)\n",
    "    print(\"Sensitivity: {:.3f}, Specificity: {:3f}\".format(sen,spe))\n",
    "    sen_perform.append(sen)\n",
    "    spe_perform.append(spe)\n",
    "\n",
    "sen_perform = np.array(sen_perform)\n",
    "spe_perform = np.array(spe_perform)\n",
    "print(\"\\nPerformance\")\n",
    "print(\"Sensitivity: {:.3f} ± {:.3f}\".format(sen_perform.mean(),sen_perform.std()))\n",
    "print(\"Specificity: {:.3f} ± {:.3f}\".format(spe_perform.mean(),spe_perform.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "\n",
    "model.fit(X,y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "L   = model.predict(X_Val)\n",
    "sen = sensitivity(y_Val,L)\n",
    "spe = sensitivity(y_Val,L,pos_label=0)\n",
    "\n",
    "print(\"Sensitivity: {:.3f}, Specificity: {:3f}\".format(sen,spe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-fraction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix as plt_cm\n",
    "\n",
    "plt_cm(model,X_Val,y_Val,cmap='inferno')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.neural_network  import MLPClassifier\n",
    "from sklearn.metrics         import recall_score as sensitivity\n",
    "from sklearn.metrics         import plot_confusion_matrix as plt_cm\n",
    "\n",
    "k       = 10\n",
    "sf      = ShuffleSplit(n_splits=k,test_size=.25)\n",
    "n_estim = [200, 500,1000,1500,2000,2500]\n",
    "gamma   = [0.0001,0.0005,0.001,0.01,0.1]\n",
    "\n",
    "@interact\n",
    "def classifiers(classifier=['SVM','RSVM','RF','MLP'],n_estim=n_estim,gamma=gamma):\n",
    "    if classifier=='SVM':\n",
    "        model = SVC(kernel='linear')\n",
    "        title = 'SVM Linear'\n",
    "    elif classifier=='RF':\n",
    "        model = RandomForestClassifier(n_estimators=n_estim)\n",
    "        title = 'Random Forest'\n",
    "    elif classifier=='RBF':\n",
    "        model = SVC(kernel='rbf',gamma=gamma)\n",
    "        title = 'SVM RBF'\n",
    "    else:\n",
    "        model = MLPClassifier(max_iter=1000)\n",
    "        title = 'Perceptron multicapa'\n",
    "    \n",
    "    sen_perform = []\n",
    "    spe_perform = []\n",
    "    for train,test in sf.split(X,y):\n",
    "        model.fit(X.iloc[train],y.iloc[train].values.ravel())\n",
    "        L   = model.predict(X.iloc[test])\n",
    "        sen = sensitivity(y.iloc[test],L)\n",
    "        spe = sensitivity(y.iloc[test],L,pos_label=0)\n",
    "        print(\"Sensitivity: {:.3f}, Specificity: {:3f}\".format(sen,spe))\n",
    "        sen_perform.append(sen)\n",
    "        spe_perform.append(spe)\n",
    "    \n",
    "    sen_perform = np.array(sen_perform)\n",
    "    spe_perform = np.array(spe_perform)\n",
    "    print(\"\\nPerformance\")\n",
    "    print(\"Sensitivity: {:.3f} ± {:.3f}\".format(sen_perform.mean(),sen_perform.std()))\n",
    "    print(\"Specificity: {:.3f} ± {:.3f}\".format(spe_perform.mean(),spe_perform.std()))\n",
    "    \n",
    "    model.fit(X,y.values.ravel())\n",
    "    \n",
    "    L   = model.predict(X_Val)\n",
    "    sen = sensitivity(y_Val,L)\n",
    "    spe = sensitivity(y_Val,L,pos_label=0)\n",
    "    \n",
    "    print(\"Sensitivity: {:.3f}, Specificity: {:3f}\".format(sen,spe))\n",
    "    \n",
    "    plt_cm(model,X_Val,y_Val,cmap='inferno')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-encounter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "model.fit(X,y.values.ravel())\n",
    "df    = pd.DataFrame({'Importancia':model.feature_importances_,'Variable':cols})\n",
    "df    = df.sort_values(by=['Importancia'])\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.barplot(y='Variable', x='Importancia', data=df, color='orange')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
